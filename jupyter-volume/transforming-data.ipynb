{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd0ad5-449a-4cd3-b3f1-d0ad9aef5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from pathlib import Path\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Write transform for image\n",
    "data_transform = transforms.Compose([\n",
    "    # Resize the images to 64x64\n",
    "    #transforms.Resize(size=(256, 256)),\n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
    "    # ????\n",
    "    #transforms.AutoAugment(),\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n",
    "])\n",
    "\n",
    "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
    "    \"\"\"Plots a series of random images from image_paths.\n",
    "\n",
    "    Will open n image paths from image_paths, transform them\n",
    "    with transform and plot them side by side.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): List of target image paths. \n",
    "        transform (PyTorch Transforms): Transforms to apply to images.\n",
    "        n (int, optional): Number of images to plot. Defaults to 3.\n",
    "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(1, 2)\n",
    "            ax[0].imshow(f) \n",
    "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "            ax[0].axis(\"off\")\n",
    "\n",
    "            # Transform and plot image\n",
    "            # Note: permute() will change shape of image to suit matplotlib \n",
    "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
    "            transformed_image = transform(f).permute(1, 2, 0) \n",
    "            ax[1].imshow(transformed_image) \n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
    "\n",
    "\n",
    "\n",
    "data_path = Path(\"../images/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "\n",
    "plot_transformed_images(image_path_list, \n",
    "                        transform=data_transform, \n",
    "                        n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc085ebd-98c2-47fa-aedd-7825f84472a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ImageFolder to create dataset(s)\n",
    "from torchvision import datasets\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# Setup train and testing paths\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
    "                                  transform=data_transform, # transforms to perform on data (images)\n",
    "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_dir, \n",
    "                                 transform=data_transform)\n",
    "\n",
    "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513b0e0-325f-430d-a964-4627a06f39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names as a list\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e5fe4-07dd-4b8d-8c7c-9972427c1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also get class names as a dict\n",
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f252b698-2213-4dbf-b37d-281cb0cd7dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the lengths\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6ebfc-f3e5-4a0d-ae31-7bc6443d4992",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_data[0][0], train_data[0][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80609c-9a4a-4a53-a432-328be515c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the order of dimensions\n",
    "img_permute = img.permute(1, 2, 0)\n",
    "\n",
    "# Print out different shapes (before and after permute)\n",
    "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.axis(\"off\")\n",
    "plt.title(class_names[label], fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702e67b-1986-40e4-8223-dc4a210432ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn train and test Datasets into DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(dataset=train_data, \n",
    "                              batch_size=1, # how many samples per batch?\n",
    "                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n",
    "                              shuffle=True) # shuffle the data?\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data, \n",
    "                             batch_size=1, \n",
    "                             num_workers=1, \n",
    "                             shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa8ecb-270c-44b2-9e68-34b8fb05e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "\n",
    "# Batch size will now be 1, try changing the batch_size parameter above and see what happens\n",
    "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda1539-b8aa-49db-aa0a-502a52bdaab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    #transforms.Resize((224, 224)),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31), # how intense \n",
    "    transforms.ToTensor() # use ToTensor() last to get everything between 0 & 1\n",
    "])\n",
    "\n",
    "# Don't need to perform augmentation on the test data\n",
    "test_transforms = transforms.Compose([\n",
    "    #transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2040181-f015-4fa0-b6d2-820ff44735f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all image paths\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "\n",
    "# Plot random images\n",
    "plot_transformed_images(\n",
    "    image_paths=image_path_list,\n",
    "    transform=train_transforms,\n",
    "    n=3,\n",
    "    seed=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811322c2-973d-490d-ab33-6acccf21cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple transform\n",
    "simple_transform = transforms.Compose([ \n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f0673-665d-49f5-85bc-6c4f4c8e406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and transform data\n",
    "from torchvision import datasets\n",
    "train_data_simple = datasets.ImageFolder(root=train_dir, transform=simple_transform)\n",
    "test_data_simple = datasets.ImageFolder(root=test_dir, transform=simple_transform)\n",
    "\n",
    "# 2. Turn data into DataLoaders\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup batch size and number of workers \n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "print(f\"Creating DataLoader's with batch size {BATCH_SIZE} and {NUM_WORKERS} workers.\")\n",
    "\n",
    "# Create DataLoader's\n",
    "train_dataloader_simple = DataLoader(train_data_simple, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     shuffle=True, \n",
    "                                     num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader_simple = DataLoader(test_data_simple, \n",
    "                                    batch_size=BATCH_SIZE, \n",
    "                                    shuffle=False, \n",
    "                                    num_workers=NUM_WORKERS)\n",
    "\n",
    "train_dataloader_simple, test_dataloader_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4363f83-712f-4e6c-819d-e47ae2f96876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1, # default\n",
    "                      padding=1), # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from? \n",
    "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "            nn.Linear(in_features=hidden_units*16*16,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv_block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.conv_block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "        # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # <- leverage the benefits of operator fusion\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  hidden_units=10, \n",
    "                  output_shape=len(train_data.classes)).to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b150f53b-95e7-473e-b88a-5451aeb9674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get a batch of images and labels from the DataLoader\n",
    "img_batch, label_batch = next(iter(train_dataloader_simple))\n",
    "\n",
    "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single image shape: {img_single.shape}\\n\")\n",
    "\n",
    "# 3. Perform a forward pass on a single image\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model_0(img_single.to(device))\n",
    "    \n",
    "# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f61b5d-c610-4c9c-ac65-9abd036c7569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install torchinfo if it's not available, import it if it is\n",
    "try: \n",
    "    import torchinfo\n",
    "except:\n",
    "    !pip install torchinfo\n",
    "    import torchinfo\n",
    "    \n",
    "from torchinfo import summary\n",
    "summary(model_0, input_size=[1, 3, 64, 64]) # do a test pass through of an example input size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdfee0d-6471-435d-8aa1-5deb20940547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Send data to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e7ac7-70fb-4b59-9756-56927079abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module):\n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "    \n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Send data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "    \n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate and accumulate accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "            \n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12561b8b-5279-48d7-8796-10238ff32c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Take in various parameters required for training and test steps\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5):\n",
    "    \n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5aab18-b97f-4c8d-b78a-9b1469d19cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Recreate an instance of TinyVGG\n",
    "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  hidden_units=10, \n",
    "                  output_shape=len(train_data.classes)).to(device)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Train model_0 \n",
    "model_0_results = train(model=model_0, \n",
    "                        train_dataloader=train_dataloader_simple,\n",
    "                        test_dataloader=test_dataloader_simple,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb095f8a-b03e-433a-b264-6211830887b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model_0_results keys\n",
    "model_0_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972f4ff-0920-4359-aa55-171009ec37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(results: dict[str, list[float]]):\n",
    "    \"\"\"Plots training curves of a results dictionary.\n",
    "\n",
    "    Args:\n",
    "        results (dict): dictionary containing list of values, e.g.\n",
    "            {\"train_loss\": [...],\n",
    "             \"train_acc\": [...],\n",
    "             \"test_loss\": [...],\n",
    "             \"test_acc\": [...]}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the loss values of the results dictionary (training and test)\n",
    "    loss = results['train_loss']\n",
    "    test_loss = results['test_loss']\n",
    "\n",
    "    # Get the accuracy values of the results dictionary (training and test)\n",
    "    accuracy = results['train_acc']\n",
    "    test_accuracy = results['test_acc']\n",
    "\n",
    "    # Figure out how many epochs there were\n",
    "    epochs = range(len(results['train_loss']))\n",
    "\n",
    "    # Setup a plot \n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label='train_loss')\n",
    "    plt.plot(epochs, test_loss, label='test_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
    "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b8916-5644-4bfe-a789-71a75b930576",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_0_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c4cdf-1440-4b9e-8a55-9c4b4f13b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training transform with TrivialAugment\n",
    "train_transform_trivial_augment = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.ToTensor() \n",
    "])\n",
    "\n",
    "# Create testing transform (no data augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfe1ea-8f4a-41c2-9437-a222dd4d38a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn image folders into Datasets\n",
    "train_data_augmented = datasets.ImageFolder(train_dir, transform=train_transform_trivial_augment)\n",
    "test_data_simple = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "train_data_augmented, test_data_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21498fa6-b2b3-4098-a40c-1a0807b1aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn Datasets into DataLoader's\n",
    "import os\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_dataloader_augmented = DataLoader(train_data_augmented, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                        shuffle=True,\n",
    "                                        num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader_simple = DataLoader(test_data_simple, \n",
    "                                    batch_size=BATCH_SIZE, \n",
    "                                    shuffle=False, \n",
    "                                    num_workers=NUM_WORKERS)\n",
    "\n",
    "train_dataloader_augmented, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dae316-7b9c-47e2-919d-cb792eb2a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_1 and send it to the target device\n",
    "torch.manual_seed(42)\n",
    "model_1 = TinyVGG(\n",
    "    input_shape=3,\n",
    "    hidden_units=10,\n",
    "    output_shape=len(train_data_augmented.classes)).to(device)\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa3172-471b-4f86-b359-3a955a92f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Train model_1\n",
    "model_1_results = train(model=model_1, \n",
    "                        train_dataloader=train_dataloader_augmented,\n",
    "                        test_dataloader=test_dataloader_simple,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c3cfb0-3b72-49a5-8b37-ecdc776b26c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8047f426-ca6d-400f-a0a4-dd08e92582e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model_0_df = pd.DataFrame(model_0_results)\n",
    "model_1_df = pd.DataFrame(model_1_results)\n",
    "model_0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca68e08-ec68-4d6f-93d4-b407e84afc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a plot \n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(model_0_df))\n",
    "\n",
    "# Plot train loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs, model_0_df[\"train_loss\"], label=\"Model 0\")\n",
    "plt.plot(epochs, model_1_df[\"train_loss\"], label=\"Model 1\")\n",
    "plt.title(\"Train Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot test loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs, model_0_df[\"test_loss\"], label=\"Model 0\")\n",
    "plt.plot(epochs, model_1_df[\"test_loss\"], label=\"Model 1\")\n",
    "plt.title(\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot train accuracy\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs, model_0_df[\"train_acc\"], label=\"Model 0\")\n",
    "plt.plot(epochs, model_1_df[\"train_acc\"], label=\"Model 1\")\n",
    "plt.title(\"Train Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot test accuracy\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs, model_0_df[\"test_acc\"], label=\"Model 0\")\n",
    "plt.plot(epochs, model_1_df[\"test_acc\"], label=\"Model 1\")\n",
    "plt.title(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe58e07-371b-4bf5-9c37-23085519c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = TinyVGG(\n",
    "    input_shape=3,\n",
    "    hidden_units=50,\n",
    "    output_shape=len(train_data_augmented.classes)).to(device)\n",
    "\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_2.parameters(), lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Train model_1\n",
    "model_2_results = train(model=model_2, \n",
    "                        train_dataloader=train_dataloader_augmented,\n",
    "                        test_dataloader=test_dataloader_simple,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")\n",
    "\n",
    "\n",
    "plot_loss_curves(model_2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbb5031-d813-4a7a-abdd-527cdc6a9aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
